{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning: Project Part 2 - Seal Call Discrimination**\n",
    "\n",
    "---\n",
    "\n",
    "**Author: Damien Farrell**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Objective**\n",
    "The aim of this project is to analyze a recorded dataset to investigate the feasibility of discriminating between different seal calls. The project is structured in steps to build a machine learning model that can potentially detect seal calls from audio recordings. While creating a fully functional detector is the ultimate goal, it may not be the final outcome of this project.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step A: Data Pre-processing**\n",
    "\n",
    "This step is completed in notebook `A. data_preprocessing.ipynb`. The file `processed_data.pkl` was produced from this notebook.\n",
    "\n",
    "#### **Step B: Model Training**\n",
    "\n",
    "This part is completed in notebook `B. model_selection.ipynb`.\n",
    "\n",
    "#### **Step C: Refine Model**\n",
    "1. **Parameter Tuning**:\n",
    "\n",
    "\n",
    "2. **Validation**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Step C: Refine Model** \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in processed data\n",
    "df = pd.read_pickle('processed_data.pkl')\n",
    "df.head()\n",
    "\n",
    "# Perform one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['Annotation'], prefix='Annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['snippet_spectrogram']].to_numpy()\n",
    "\n",
    "# \"Flatten\" the (3742, 1) array to (3742,)\n",
    "X = X.ravel()\n",
    "print(X.shape)\n",
    "\n",
    "# Stack along a new axis to get shape (3742, 42, 84)\n",
    "X = np.stack(X, axis=0)\n",
    "print(X.shape)\n",
    "\n",
    "# Reshape to 2D for MinMaxScaler\n",
    "X_reshaped = X.reshape(-1, X.shape[-2])  # Shape: (3742 * 42, 84)\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_reshaped)\n",
    "\n",
    "# Reshape back to the original shape\n",
    "X = X_scaled.reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, which='loss'):\n",
    "    plt.plot(history.history[which], label='train')\n",
    "    try:\n",
    "        plt.plot(history.history['val_' + which], label='Validation Loss')\n",
    "    except:\n",
    "        pass\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(which)\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "    try:\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    except:\n",
    "        pass\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot():\n",
    "    # Predict probabilities and convert to class predictions\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Convert y_test one-hot to integer-encoded labels\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Extract the real class names\n",
    "    class_names = [col.replace(\"Annotation_\", \"\") for col in y_test.columns]\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names,\n",
    "                cmap=\"viridis\", ax=ax)\n",
    "\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack(df['snippet_spectrogram'].values)\n",
    "y = df[[col for col in df.columns if col.startswith(\"Annotation_\")]]  # Select annotation columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 1: CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define focal loss\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        loss = -y_true * alpha * K.pow(1 - y_pred, gamma) * K.log(y_pred)\n",
    "        return K.mean(loss, axis=-1)\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=3, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(42, 84, 1)))\n",
    "    \n",
    "    # Add convolutional layers\n",
    "    for i in range(hp.Int(\"conv_layers\", 1, 3)):  # Search for 1-3 Conv layers\n",
    "        model.add(\n",
    "            layers.Conv2D(\n",
    "                filters=hp.Int(f\"filters_{i}\", min_value=16, max_value=128, step=16),\n",
    "                kernel_size=hp.Choice(f\"kernel_size_{i}\", values=[3, 5]),\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "            )\n",
    "        )\n",
    "        model.add(layers.MaxPooling2D())\n",
    "\n",
    "    # Flatten + Dense\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            units=hp.Int(\"dense_units\", min_value=64, max_value=256, step=32),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "    # Adjust final layer based on number of classes (or multi-label dimension)\n",
    "    num_classes = len(np.unique(stratify_labels))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    loss_type = hp.Choice(\"loss_type\", [\"focal\", \"categorical_crossentropy\"])\n",
    "    if loss_type == \"focal\":\n",
    "        chosen_loss = focal_loss(gamma=2.0, alpha=0.25)  # Custom focal loss\n",
    "    else:\n",
    "        chosen_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Choice(\"learning_rate\", values=[1e-3, 1e-4, 1e-5])\n",
    "        ),\n",
    "        loss=chosen_loss,\n",
    "        metrics=[\n",
    "            \"accuracy\",\n",
    "            tf.keras.metrics.Precision(thresholds=0.5, name=\"precision\"),\n",
    "            tf.keras.metrics.Recall(thresholds=0.5, name=\"recall\"),\n",
    "            tf.keras.metrics.AUC(multi_label=True, name=\"auc\"),\n",
    "            tf.keras.metrics.F1Score(threshold=0.5, average=\"macro\", name=\"f1_score\"),\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "X = np.stack(df['snippet_spectrogram'].values)\n",
    "y = df[[col for col in df.columns if col.startswith(\"Annotation_\")]].values\n",
    "\n",
    "stratify_labels = np.argmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=stratify_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuner = kt.Hyperband(\n",
    "#    build_model,\n",
    "#    objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "#    max_epochs=20,\n",
    "#    factor=3,\n",
    "#    directory=\"tuner_results\",\n",
    "#    project_name=\"spectrogram_tuning\",\n",
    "#)\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=20,  # Explicit number of trials\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"bayesian_search\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    epochs=10,  # or a different number for the tuning phase\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best loss_type:\", best_hp.get(\"loss\"))\n",
    "print(\"Best learning_rate:\", best_hp.get(\"learning_rate\"))\n",
    "print(\"Best conv_layers:\", best_hp.get(\"conv_layers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and evaluate the \"best model\" on the validation set\n",
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "best_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop_callback]\n",
    ")\n",
    "val_results = best_model.evaluate(X_val, y_val, verbose=0, return_dict=True)\n",
    "print(\"Validation Results after Tuning:\", val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold_idx, (train_index, val_index) in enumerate(kf.split(X, stratify_labels), 1):\n",
    "    print(f\"\\n--- Fold {fold_idx} ---\")\n",
    "    X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
    "    y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
    "\n",
    "    # Build a new model with the best hyperparameters from the tuner\n",
    "    model_cv = tuner.hypermodel.build(best_hp)\n",
    "\n",
    "    # You could use a different patience if you like\n",
    "    early_stop_cv = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=20, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Train the best model on this fold\n",
    "    history = model_cv.fit(\n",
    "        X_train_cv, y_train_cv,\n",
    "        epochs=20,\n",
    "        validation_data=(X_val_cv, y_val_cv),\n",
    "        callbacks=[early_stop_cv],\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Evaluate on the validation portion of this fold\n",
    "    results = model_cv.evaluate(X_val_cv, y_val_cv, verbose=0, return_dict=True)\n",
    "    fold_accuracies.append(results[\"accuracy\"])\n",
    "    fold_f1_scores.append(results[\"f1_score\"])\n",
    "\n",
    "    # Clear session to avoid clutter\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nAvg accuracy over folds: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "print(f\"Avg F1 over folds:       {np.mean(fold_f1_scores):.4f} ± {np.std(fold_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the training & validation accuracy\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1) Predict on the validation set\n",
    "y_pred_probs = best_model.predict(X_val)\n",
    "\n",
    "# Convert probabilities to predicted class indices\n",
    "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Convert one-hot true labels to class indices\n",
    "y_true_labels = np.argmax(y_val, axis=1)\n",
    "\n",
    "# 9.2) Classification report\n",
    "print(\"\\nClassification Report (Validation Set):\\n\")\n",
    "print(classification_report(y_true_labels, y_pred_labels))\n",
    "\n",
    "# 9.3) Confusion matrix\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d',\n",
    "            xticklabels=np.unique(y_true_labels),\n",
    "            yticklabels=np.unique(y_true_labels))\n",
    "plt.title('Confusion Matrix (Validation Set)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = best_model.evaluate(X_val, y_val, verbose=0, return_dict=True)\n",
    "print(\"\\nFinal Validation Metrics:\")\n",
    "for metric_name, metric_value in final_results.items():\n",
    "    print(f\"{metric_name}: {metric_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### **References**\n",
    "\n",
    "1. [Bird Song Dataset on Kaggle](https://www.kaggle.com/code/sophiagnetneva/cnn-for-sound-classification-bird-calls-90)\n",
    "1.\n",
    "1.\n",
    "1.\n",
    "1.\n",
    "1.\n",
    "1.\n",
    "1.\n",
    "1.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
